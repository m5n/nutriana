#!/usr/bin/perl
#
# Generates the SQL file for a specific RDBMS.
# This file is part of http://github/m5n/nutriana

use strict;
use warnings;



# Change these to suit your needs.
# TODO: move to properties file
my $DB_USER = "food";
my $DB_PWD = "food";
my $DB_SERVER = "localhost";


use strict;
use warnings;
use JSON;


my $dbid = $ARGV[0];
my $nutdbid = $ARGV[1];
my $outfile = $ARGV[2];
die "Usage: $0 rdbmsid nutdbid\n" if !$dbid or !$nutdbid;


my $project_url = "http://github.com/m5n/nutriana";
my $file = "../$nutdbid/schema.json";
my $json = do { local $/ = undef; open my $fh, "<", $file or die "Could not open $file: $!"; <$fh>; };
my $data = decode_json($json);
my $header = $data->{"description"} . " (" . $data->{"url"} . ")";
my $header_length = length($header);


# Output header.
print sql_comment("="x$header_length). "\n";
print sql_comment($header) . "\n";
print sql_comment("This file was generated by $project_url") . "\n";
print sql_comment("Run this SQL with an account that has admin priviledges, e.g.: " . sql_how_to_run_as_admin($DB_USER, $outfile)) . "\n";
print sql_comment("="x$header_length). "\n\n";


# Set up user and database.
print sql_recreate_database_and_user_to_access_it($nutdbid, $DB_USER, $DB_PWD, $DB_SERVER) . "\n\n";


# Set up tables.
# All tables must be defined before we can add foreign keys.
# To avoid having to figure out which tables should have their data loaded before other tables, load all data before adding foreign keys.
# Some databases can only import data fast if there are no constraints or triggers yet (e.g. Oracle), so load data before adding primary or foreign keys.
# Some databases support only case sensitive constraints (e.g. Oracle) and not all nutrient databases specify values with consistent casing (e.g. usda_nndsr), so do case conversion before adding primary or foreign keys.  (And because of the above, we cannot use triggers for this.)
# Some databases do not interpret empty string as null (e.g. MySQL) and some nutrient databases use empty string in nullable columns (e.g. usda_nndsr) causing problems with foreign keys, so convert empty strings to null to avoid the errors.
# So:
# 1. create tables
# 2. import data
# 3. fix casing and empty string issues
# 4. add primary keys
# 5. add foreign keys

# Create tables.
foreach (@{$data->{"tables"}}) {
    my %table = %{$_};
    my $table_name = $table{"table"};
    my @fields = @{$table{"fields"}};
    my $idx = 0;

    print sql_comment($table{"description"}) . "\n";
    print sql_create_table_start($table_name) . "\n";
    foreach (@fields) {
        my %field = %{$_};
        my $datatype = sql_datatype_def($field{"type"}, $field{"size"}, 1);
        print "    " . sql_field_def($field{"name"}, $datatype, $field{"allows_null"});
        print "," if $idx != $#fields;
        print "   " . sql_comment($field{"description"}) . "\n";
        $idx++;
    }
    print sql_create_table_end() . "\n\n";
}

# Import data.
`mkdir -p ../$nutdbid/dist/data.processed`;   # Keep things tidy and gather all trimmed files into a subdir.
$/ = $data->{"data_file_record_separator"};   # Some data file entries span multiple lines (probably due to a typo), so use custom record separator.
foreach (@{$data->{"tables"}}) {
    my %table = %{$_};
    my $table_name = $table{"table"};
    my @fieldinfo = ();
    my $datafile = "../$nutdbid/data/" . $table{"file"};
    my $trimmedfile = $datafile;   # File used in sql_load_file below.
    $trimmedfile =~ s/\s/_/g;
    $trimmedfile =~ s|/data/|/dist/data.processed/|g;
    $trimmedfile .= ".trimmed";
    my $line_separator = "\\n";   # \\r, if any, will be removed via the .trimmed file.

    # Convert files to remove trailing whitespace and empty lines.
    if (!-e $trimmedfile) {   # Only convert once.
        open INFILE, "<", $datafile or die "Could not open $datafile: $!";
        open OUTFILE, ">", $trimmedfile or die "Could not open $trimmedfile: $!";
        # TODO: doing this while loop ends up setting @{$data->{"tables"}}[0] to undefined, leading to trouble below.  Why?
        while (<INFILE>) {
            $_ =~ s/[\r\n]//g;   # Even though a custom record separator is used, make sure to remove any remaining "regular" line endings.
            $_ =~ s/\s+$//g;   # Remove trailing space.
            next if &empty_record($_, $data->{"field_separator"});
            print OUTFILE $_ . "\n" if length($_) > 0;   # Interpreted version of $line_separator.   # TODO: find Perl function to convert "\\n" -> "\n".
        }
        close INFILE;
        close OUTFILE;
    }

    foreach (@{$table{"fields"}}) {
        my %field = %{$_};

        push @fieldinfo, {"name" => $field{"name"}, "type" => $field{"type"}, "size" => $field{"size"}};
    }

    print sql_comment("Load data into $table_name") . "\n";
    print sql_load_file($nutdbid, $DB_USER, $DB_PWD, $trimmedfile, $table_name, $data->{"field_separator"}, $data->{"text_separator"}, $line_separator, $data->{"ignore_header_lines"}, @fieldinfo) . "\n";

    # Assert all records were loaded.  Make sure a SQL error is generated if the count is off.
    print sql_comment("Assert all " . $table{"records"} . " records were loaded") . "\n";
    print sql_assert_record_count($table_name, $table{"records"}) . "\n\n";
}

$data = decode_json($json);   # TODO: without this, we get this error: Can't use an undefined value as a HASH reference at ./generate_sql.pl line 120, which is the "my %table = %{$_};" line below.

# Fix casing and empty string issues.
print sql_comment("Correct data inconsistencies, if any") . "\n";
foreach (@{$data->{"tables"}}) {
    my %table = %{$_};
    my $table_name = $table{"table"};

    foreach (@{$table{"fields"}}) {
        my %field = %{$_};

        print sql_convert_to_uppercase($table_name, $field{"name"}) . "\n" if $field{"convert_to_uppercase"};
        print sql_convert_empty_string_to_null($table_name, $field{"name"}) . "\n" if $field{"convert_empty_string_to_null"};
    }
}
print "\n";

# Add primary keys.
print sql_comment("Add primary keys") . "\n";
foreach (@{$data->{"tables"}}) {
    my %table = %{$_};
    my $table_name = $table{"table"};
    my @primary_keys = ();

    foreach (@{$table{"fields"}}) {
        my %field = %{$_};

        push @primary_keys, $field{"name"} if $field{"is_primary_key"};
    }

    print sql_add_primary_keys($table_name, @primary_keys) . "\n" if $#primary_keys >= 0;
}
print "\n";

# Add foreign keys.
print sql_comment("Add foreign keys") . "\n";
foreach (@{$data->{"tables"}}) {
    my %table = %{$_};
    my $table_name = $table{"table"};

    foreach (@{$table{"fields"}}) {
        my %field = %{$_};

        print sql_add_foreign_key($table_name, $field{"name"}, $field{"foreign_key"}) . "\n" if $field{"foreign_key"};
    }
}

sub empty_record {
  my ($record_str, $field_separator) = @_;

  # This doesn't work, neither with or without \Q: $record_str =~ m/^\Q$field_separator+$/;
  # Do it the hard--and non-Perl--way.
  my $copy = $record_str;
  while ((my $idx = index($copy, $field_separator)) >= 0) {
    $copy = substr($copy, 0, $idx) . substr($copy, $idx + length($field_separator));
  }

  return length($copy) == 0;
}
